{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate HACT graph on one image\n",
    "Written for debugging problem seen on entire data set where cell graph generation fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from dgl.data.utils import save_graphs\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from histocartography.preprocessing import (\n",
    "    VahadaneStainNormalizer,         # stain normalizer\n",
    "    NucleiExtractor,                 # nuclei detector \n",
    "    DeepFeatureExtractor,            # feature extractor \n",
    "    KNNGraphBuilder,                 # kNN graph builder\n",
    "    ColorMergedSuperpixelExtractor,  # tissue detector\n",
    "    DeepFeatureExtractor,            # feature extractor\n",
    "    RAGGraphBuilder,                 # build graph\n",
    "    AssignmnentMatrixBuilder         # assignment matrix \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRACS subtype to 7-class label \n",
    "TUMOR_TYPE_TO_LABEL = {\n",
    "    'N': 0,\n",
    "    'PB': 1,\n",
    "    'UDH': 2,\n",
    "    'ADH': 3,\n",
    "    'FEA': 4,\n",
    "    'DCIS': 5,\n",
    "    'IC': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NR_PIXELS = 50000\n",
    "MAX_NR_PIXELS = 50000000  \n",
    "STAIN_NORM_TARGET_IMAGE = '/nadeem_lab/Eliram/repos/hact-net/data/target.png'  # define stain normalization target image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HACTBuilding:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # 1. define stain normalizer \n",
    "        self.normalizer = VahadaneStainNormalizer(target_path=STAIN_NORM_TARGET_IMAGE)\n",
    "\n",
    "        # 2. define CG builders\n",
    "        self._build_cg_builders()\n",
    "\n",
    "        # 3. define TG builders \n",
    "        self._build_tg_builders()\n",
    "\n",
    "        # 4. define assignment matrix builder\n",
    "        self.assignment_matrix_builder = AssignmnentMatrixBuilder()\n",
    "\n",
    "        # 5. define var to store image IDs that failed (for whatever reason)\n",
    "        self.image_ids_failing = []\n",
    "\n",
    "    def _build_cg_builders(self):\n",
    "        # a define nuclei extractor\n",
    "        self.nuclei_detector = NucleiExtractor()\n",
    "\n",
    "        # b define feature extractor: Extract patches of 72x72 pixels around each\n",
    "        # nucleus centroid, then resize to 224 to match ResNet input size.\n",
    "        self.nuclei_feature_extractor = DeepFeatureExtractor(\n",
    "            architecture='resnet34',\n",
    "            patch_size=72,\n",
    "            resize_size=224\n",
    "        )\n",
    "\n",
    "        # c define k-NN graph builder with k=5 and thresholding edges longer\n",
    "        # than 50 pixels. Add image size-normalized centroids to the node features.\n",
    "        # For e.g., resulting node features are 512 features from ResNet34 + 2\n",
    "        # normalized centroid features.\n",
    "        self.knn_graph_builder = KNNGraphBuilder(k=5, thresh=50, add_loc_feats=True)\n",
    "\n",
    "    def _build_tg_builders(self):\n",
    "        # a define nuclei extractor    \n",
    "        self.tissue_detector = ColorMergedSuperpixelExtractor(\n",
    "            superpixel_size=500,\n",
    "            compactness=20,\n",
    "            blur_kernel_size=1,\n",
    "            threshold=0.05,\n",
    "            downsampling_factor=4\n",
    "        )\n",
    "\n",
    "        # b define feature extractor: Extract patches of 144x144 pixels all over \n",
    "        # the tissue regions. Each patch is resized to 224 to match ResNet input size.\n",
    "        self.tissue_feature_extractor = DeepFeatureExtractor(\n",
    "            architecture='resnet34',\n",
    "            patch_size=144,\n",
    "            resize_size=224\n",
    "        )\n",
    "\n",
    "        # c define RAG builder. Append normalized centroid to the node features. \n",
    "        self.rag_graph_builder = RAGGraphBuilder(add_loc_feats=True)\n",
    "\n",
    "    def _build_cg(self, image):\n",
    "        nuclei_map, nuclei_centroids = self.nuclei_detector.process(image)\n",
    "        features = self.nuclei_feature_extractor.process(image, nuclei_map)\n",
    "        graph = self.knn_graph_builder.process(nuclei_map, features)\n",
    "        return graph, nuclei_centroids\n",
    "\n",
    "    def _build_tg(self, image):\n",
    "        superpixels, _ = self.tissue_detector.process(image)\n",
    "        features = self.tissue_feature_extractor.process(image, superpixels)\n",
    "        graph = self.rag_graph_builder.process(superpixels, features)\n",
    "        return graph, superpixels\n",
    "\n",
    "    def process(self, image_path, save_path, split):\n",
    "        # 1. get image path\n",
    "        subdirs = os.listdir(image_path)\n",
    "        image_fnames = []\n",
    "        for subdir in (subdirs + ['']):  # look for all the subdirs AND the image path\n",
    "            image_fnames += glob(os.path.join(image_path, subdir, '*.png'))\n",
    "    \n",
    "    def _valid_image(self, nr_pixels):\n",
    "        if nr_pixels > MIN_NR_PIXELS and nr_pixels < MAX_NR_PIXELS:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _exists(self, cg_out, tg_out, assign_out):\n",
    "        if os.path.isfile(cg_out) and os.path.isfile(tg_out) and os.path.isfile(assign_out):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_exists() missing 1 required positional argument: 'assign_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_919019/2459499720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0massign_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'assignment_matrices'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0m_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcg_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtg_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massign_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: _exists() missing 1 required positional argument: 'assign_out'"
     ]
    }
   ],
   "source": [
    "image_path=\"/nadeem_lab/datasets/BRACS/train/4_FEA/BRACS_1815_FEA_1.png\"\n",
    "save_path=\"~/temp\"\n",
    "split='train'\n",
    "# a. load image & check if already there \n",
    "_, image_name = os.path.split(image_path)\n",
    "image = np.array(Image.open(image_path))\n",
    "nr_pixels = image.shape[0] * image.shape[1]\n",
    "image_label = TUMOR_TYPE_TO_LABEL[image_name.split('_')[2]]\n",
    "cg_out = os.path.join(save_path, 'cell_graphs', split, image_name.replace('.png', '.bin'))\n",
    "tg_out = os.path.join(save_path, 'tissue_graphs', split, image_name.replace('.png', '.bin'))\n",
    "assign_out = os.path.join(save_path, 'assignment_matrices', split, image_name.replace('.png', '.h5'))\n",
    "\n",
    "HACTBuilding.\n",
    "HACTBUILDING_exists(cg_out, tg_out, assign_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if file was not already created + not too big + not too small, then process \n",
    "if not _exists(cg_out, tg_out, assign_out) and _valid_image(nr_pixels):\n",
    "\n",
    "    # b. stain norm the image \n",
    "    try: \n",
    "        image = self.normalizer.process(image)\n",
    "    except:\n",
    "        print('Warning: {} failed during stain normalization.'.format(image_path))\n",
    "        self.image_ids_failing.append(image_path)\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        cell_graph, nuclei_centroid = self._build_cg(image)\n",
    "        save_graphs(\n",
    "            filename=cg_out,\n",
    "            g_list=[cell_graph],\n",
    "            labels={\"label\": torch.tensor([image_label])}\n",
    "        )\n",
    "    except:\n",
    "        print('Warning: {} failed during cell graph generation.'.format(image_path))\n",
    "        self.image_ids_failing.append(image_path)\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        tissue_graph, tissue_map = self._build_tg(image)\n",
    "        save_graphs(\n",
    "            filename=tg_out,\n",
    "            g_list=[tissue_graph],\n",
    "            labels={\"label\": torch.tensor([image_label])}\n",
    "        )\n",
    "    except:\n",
    "        print('Warning: {} failed during tissue graph generation.'.format(image_path))\n",
    "        self.image_ids_failing.append(image_path)\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        assignment_matrix = self.assignment_matrix_builder.process(nuclei_centroid, tissue_map)\n",
    "        with h5py.File(assign_out, \"w\") as output_file:\n",
    "            output_file.create_dataset(\n",
    "                \"assignment_matrix\",\n",
    "                data=assignment_matrix,\n",
    "                compression=\"gzip\",\n",
    "                compression_opts=9,\n",
    "            )\n",
    "    except:\n",
    "        print('Warning: {} failed during assignment matrix generation.'.format(image_path))\n",
    "        self.image_ids_failing.append(image_path)\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    print('Image:', image_path, ' was already processed or is too large/small.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "995c5d1376a1b545e5793d8c9222fdcba04000266d6f2b0b015a9e078884360e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('hactnet_hpc4': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
