{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ed9b9a-b32e-4d36-b655-9d9d020c0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import os\n",
    "import uuid\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import argparse\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "from histocartography.ml import CellGraphModel, TissueGraphModel, HACTModel\n",
    "\n",
    "from dataloader import make_data_loader\n",
    "\n",
    "# cuda support\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "DEVICE = 'cuda:0' if IS_CUDA else 'cpu'\n",
    "NODE_DIM = 514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21adc4e-41a8-47bc-abe9-d9e5c1c35293",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fpath = '/nadeem_lab/Eliram/repos/hact-net/core/config/bracs_hact_7_classes_pna.yml'\n",
    "with open(config_fpath, 'r') as f:\n",
    "  config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3168d88-c320-4fb5-8383-d7fd1530f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fpath = '/nadeem_lab/Eliram/repos/hact-net/core/config/bracs_cggnn_7_classes_pna.yml'\n",
    "with open(config_fpath, 'r') as f:\n",
    "  config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e96e4d4-ff7a-49c1-bbd6-0f29c2256043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ''\n",
    "model_path = os.path.join(model_path, str(uuid.uuid4()))\n",
    "os.makedirs(model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b294455-3377-4820-8c91-7c90e7f4d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "cg_path = '/nadeem_lab/Eliram/repos/hact-net/data/hact-net-data/cell_graphs'\n",
    "tg_path = '/nadeem_lab/Eliram/repos/hact-net/data/hact-net-data/tissue_graphs'\n",
    "assign_mat_path = '/nadeem_lab/Eliram/repos/hact-net/data/hact-net-data/assignment_matrices'\n",
    "batch_size = 8\n",
    "learning_rate = 0.0005\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b50c48a-c6ab-4b57-b854-f46e8ac8929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "cg_path = '/nadeem_lab/Eliram/repos/hact-net/data/hact-net-data/cell_graphs'\n",
    "tg_path = ''\n",
    "assign_mat_path = ''\n",
    "batch_size = 8\n",
    "learning_rate = 0.0005\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b287530-5eab-445a-b2d3-a32d2a32d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = make_data_loader(\n",
    "    cg_path=os.path.join(cg_path, 'train') if cg_path is not None else None,\n",
    "    tg_path=os.path.join(tg_path, 'train') if tg_path is not None else None,\n",
    "    assign_mat_path=os.path.join(assign_mat_path, 'train') if assign_mat_path is not None else None,\n",
    "    batch_size=batch_size,\n",
    "    load_in_ram='in_ram',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fff1d1-7d78-4dc0-9bb5-b488c191c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare model\n",
    "model = HACTModel(\n",
    "    cg_gnn_params=config['cg_gnn_params'],\n",
    "    tg_gnn_params=config['tg_gnn_params'],\n",
    "    classification_params=config['classification_params'],\n",
    "    cg_node_dim=NODE_DIM,\n",
    "    tg_node_dim=NODE_DIM,\n",
    "    num_classes=7\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c86265-fdf3-474a-84ed-286153776416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df3810b-0f58-48fa-8f95-151c5783d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9875918-ca5e-4f59-81cc-6ba773c3352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 0:   0%|          | 0/119 [00:42<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The CG and TG are not the same. There was an issue while creating HACT.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_190651/922312954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch training {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 1. forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nadeem_lab/miniconda3/envs/hactnet_hpc4/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nadeem_lab/miniconda3/envs/hactnet_hpc4/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nadeem_lab/miniconda3/envs/hactnet_hpc4/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nadeem_lab/miniconda3/envs/hactnet_hpc4/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nadeem_lab/miniconda3/envs/hactnet_hpc4/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nadeem_lab/Eliram/repos/hact-net/core/dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mtg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtissue_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0massign_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_matrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_graph_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtissue_graph_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The CG and TG are not the same. There was an issue while creating HACT.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_graph_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The CG and TG are not the same. There was an issue while creating HACT."
     ]
    }
   ],
   "source": [
    "logger='none'\n",
    "\n",
    "# training loop\n",
    "step = 0\n",
    "best_val_loss = 10e5\n",
    "best_val_accuracy = 0.\n",
    "best_val_weighted_f1_score = 0.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # A.) train for 1 epoch\n",
    "    model = model.to(DEVICE)\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader, desc='Epoch training {}'.format(epoch), unit='batch'):\n",
    "\n",
    "        # 1. forward pass\n",
    "        labels = batch[-1]\n",
    "        data = batch[:-1]\n",
    "        logits = model(*data)\n",
    "\n",
    "        # 2. backward pass\n",
    "        loss = loss_fn(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 3. log training loss \n",
    "        if logger == 'mlflow':\n",
    "            mlflow.log_metric('train_loss', loss.item(), step=step)\n",
    "\n",
    "        # 4. increment step\n",
    "        step += 1\n",
    "\n",
    "    # B.) validate\n",
    "    model.eval()\n",
    "    all_val_logits = []\n",
    "    all_val_labels = []\n",
    "    for batch in tqdm(val_dataloader, desc='Epoch validation {}'.format(epoch), unit='batch'):\n",
    "        labels = batch[-1]\n",
    "        data = batch[:-1]\n",
    "        with torch.no_grad():\n",
    "            logits = model(*data)\n",
    "        all_val_logits.append(logits)\n",
    "        all_val_labels.append(labels)\n",
    "\n",
    "    all_val_logits = torch.cat(all_val_logits).cpu()\n",
    "    all_val_preds = torch.argmax(all_val_logits, dim=1)\n",
    "    all_val_labels = torch.cat(all_val_labels).cpu()\n",
    "\n",
    "    # compute & store loss + model\n",
    "    with torch.no_grad():\n",
    "        loss = loss_fn(all_val_logits, all_val_labels).item()\n",
    "    if logger == 'mlflow':\n",
    "        mlflow.log_metric('val_loss', loss, step=step)\n",
    "    if loss < best_val_loss:\n",
    "        best_val_loss = loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_path, 'model_best_val_loss.pt'))\n",
    "\n",
    "    # compute & store accuracy + model\n",
    "    all_val_preds = all_val_preds.detach().numpy()\n",
    "    all_val_labels = all_val_labels.detach().numpy()\n",
    "    accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    if logger == 'mlflow':\n",
    "        mlflow.log_metric('val_accuracy', accuracy, step=step)\n",
    "    if accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), os.path.join(model_path, 'model_best_val_accuracy.pt'))\n",
    "\n",
    "    # compute & store weighted f1-score + model\n",
    "    weighted_f1_score = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
    "    if logger == 'mlflow':\n",
    "        mlflow.log_metric('val_weighted_f1_score', weighted_f1_score, step=step)\n",
    "    if weighted_f1_score > best_val_weighted_f1_score:\n",
    "        best_val_weighted_f1_score = weighted_f1_score\n",
    "        torch.save(model.state_dict(), os.path.join(model_path, 'model_best_val_weighted_f1_score.pt'))\n",
    "\n",
    "    print('Val loss {}'.format(loss))\n",
    "    print('Val weighted F1 score {}'.format(weighted_f1_score))\n",
    "    print('Val accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55912590-f56b-4e0d-abf1-4c4dd0e2137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      "    the given dataset.\n",
      "\n",
      "    The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "    iterable-style datasets with single- or multi-process loading, customizing\n",
      "    loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "    See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "    Args:\n",
      "        dataset (Dataset): dataset from which to load the data.\n",
      "        batch_size (int, optional): how many samples per batch to load\n",
      "            (default: ``1``).\n",
      "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "            at every epoch (default: ``False``).\n",
      "        sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "            samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "            implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "        batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "            returns a batch of indices at a time. Mutually exclusive with\n",
      "            :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "            and :attr:`drop_last`.\n",
      "        num_workers (int, optional): how many subprocesses to use for data\n",
      "            loading. ``0`` means that the data will be loaded in the main process.\n",
      "            (default: ``0``)\n",
      "        collate_fn (callable, optional): merges a list of samples to form a\n",
      "            mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "            map-style dataset.\n",
      "        pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "            into CUDA pinned memory before returning them.  If your data elements\n",
      "            are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "            see the example below.\n",
      "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "            if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "            the size of dataset is not divisible by the batch size, then the last batch\n",
      "            will be smaller. (default: ``False``)\n",
      "        timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "            from workers. Should always be non-negative. (default: ``0``)\n",
      "        worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
      "            worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "            input, after seeding and before data loading. (default: ``None``)\n",
      "        generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "            by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "            `base_seed` for workers. (default: ``None``)\n",
      "        prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\n",
      "            in advance by each worker. ``2`` means there will be a total of\n",
      "            2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
      "        persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      "            the worker processes after a dataset has been consumed once. This allows to\n",
      "            maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "\n",
      "\n",
      "    .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "                 cannot be an unpicklable object, e.g., a lambda function. See\n",
      "                 :ref:`multiprocessing-best-practices` on more details related\n",
      "                 to multiprocessing in PyTorch.\n",
      "\n",
      "    .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "                 When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "                 it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "                 rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "                 configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "                 trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "                 loading to avoid duplicate data.\n",
      "\n",
      "                 However, if sharding results in multiple workers having incomplete last batches,\n",
      "                 this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "                 be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "                 dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "                 cases in general.\n",
      "\n",
      "                 See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "                 :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "                 `Multi-process data loading`_.\n",
      "\n",
      "    .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "                 :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070a81f-f806-4ecc-8b7a-65e1007772c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '_IterableDataset_len_called',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_get_iterator',\n",
       " '_index_sampler',\n",
       " '_iterator',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'check_worker_number_rationality',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'generator',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'persistent_workers',\n",
       " 'pin_memory',\n",
       " 'prefetch_factor',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "995c5d1376a1b545e5793d8c9222fdcba04000266d6f2b0b015a9e078884360e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('hactnet_hpc4': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
